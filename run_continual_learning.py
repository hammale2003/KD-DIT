#!/usr/bin/env python3
"""
Script pour ex√©cuter les exp√©riences d'apprentissage continu
Divise les 16 classes RVL-CDIP en t√¢ches s√©quentielles et √©value l'oubli catastrophique
"""

import torch
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import json
import copy
from typing import Dict, List
import matplotlib.pyplot as plt
from tqdm import tqdm
import random
from collections import defaultdict
import os
from datetime import datetime

# Imports du projet
from models import load_trained_student_model
from test_student_model import extract_ocr_with_easyocr, test_image_with_ocr_data
from config import DEVICE
from PIL import Image
import glob


class ContinualLearningExperiment:
    """Exp√©rience d'apprentissage continu simplifi√©e"""
    
    def __init__(self, images_dir: str = "."):
        self.images_dir = images_dir
        
        # Configuration
        self.class_names = [
            "letter", "form", "email", "handwritten", "advertisement", 
            "scientific report", "scientific publication", "specification", 
            "file folder", "news article", "budget", "invoice", 
            "presentation", "questionnaire", "resume", "memo"
        ]
        
        # Division en t√¢ches (4 t√¢ches de 4 classes chacune)
        self.tasks = self._create_tasks()
        
        # Charger le mod√®le √©tudiant entra√Æn√©
        print("Chargement du mod√®le √©tudiant...")
        self.student_model, self.student_processor = load_trained_student_model("student_model.pth")
        
        # Sauvegarder l'√©tat initial
        self.initial_state = copy.deepcopy(self.student_model.state_dict())
        
        # R√©sultats
        self.results = {
            'task_accuracies': defaultdict(list),
            'forgetting_metrics': {},
            'model_states': {}  # Pour sauvegarder l'√©tat apr√®s chaque t√¢che
        }
        
    def _create_tasks(self) -> List[Dict]:
        """Cr√©er les d√©finitions de t√¢ches"""
        tasks = []
        
        for task_id in range(4):  # 4 t√¢ches
            start_class = task_id * 4
            end_class = (task_id + 1) * 4
            
            task_classes = list(range(start_class, end_class))
            task_class_names = [self.class_names[i] for i in task_classes]
            
            tasks.append({
                'task_id': task_id,
                'name': f'Task_{task_id}',
                'classes': task_classes,
                'class_names': task_class_names,
                'description': f'Classes {start_class}-{end_class-1}: {", ".join(task_class_names)}'
            })
            
        return tasks
    
    def simulate_task_data(self, task_id: int, num_samples: int = 20) -> List[Dict]:
        """Simuler des donn√©es pour une t√¢che sp√©cifique"""
        print(f"Simulation de donn√©es pour {self.tasks[task_id]['name']}")
        
        # Utiliser les images disponibles et simuler des labels
        available_images = glob.glob(os.path.join(self.images_dir, "*.jpg"))
        
        if not available_images:
            print("‚ö†Ô∏è Aucune image trouv√©e. Utilisation de donn√©es fictives.")
            return []
        
        # Prendre les images disponibles et assigner des labels de fa√ßon cyclique
        task_classes = self.tasks[task_id]['classes']
        simulated_data = []
        
        for i in range(min(num_samples, len(available_images) * len(task_classes))):
            image_path = available_images[i % len(available_images)]
            assigned_class = task_classes[i % len(task_classes)]
            
            simulated_data.append({
                'image_path': image_path,
                'label': assigned_class,
                'class_name': self.class_names[assigned_class]
            })
        
        print(f"G√©n√©r√© {len(simulated_data)} √©chantillons pour la t√¢che {task_id}")
        return simulated_data
    
    def run_sequential_learning(self, mitigation: str = "naive"):
        """Ex√©cuter l'apprentissage s√©quentiel avec technique de mitigation"""
        print(f"\n{'='*60}")
        print(f"APPRENTISSAGE S√âQUENTIEL - Technique: {mitigation.upper()}")
        print(f"{'='*60}")
        
        # R√©initialiser le mod√®le
        self.student_model.load_state_dict(self.initial_state)
        
        # Simuler l'entra√Ænement sur chaque t√¢che
        for task_id in range(len(self.tasks)):
            print(f"\n--- T√¢che {task_id + 1}/{len(self.tasks)} ---")
            print(f"Classes: {self.tasks[task_id]['class_names']}")
            
            # Simuler des donn√©es d'entra√Ænement
            training_data = self.simulate_task_data(task_id, num_samples=10)
            
            # Simuler l'entra√Ænement (ici on ne fait que charger les donn√©es)
            print(f"‚úÖ Entra√Ænement simul√© sur {len(training_data)} √©chantillons")
            
            # √âvaluation simul√©e
            task_accuracies = self._simulate_evaluation(task_id)
            
            # Stocker les r√©sultats
            for task_name, accuracy in task_accuracies.items():
                task_num = int(task_name.split('_')[1])
                self.results['task_accuracies'][task_num].append(accuracy)
        
        # R√©sultats finaux
        print(f"\n{'='*60}")
        print("R√âSULTATS FINAUX")
        print(f"{'='*60}")
        
        final_accuracies = {}
        for task_id in range(len(self.tasks)):
            if task_id in self.results['task_accuracies']:
                final_accuracies[f"task_{task_id}"] = self.results['task_accuracies'][task_id][-1]
        
        avg_accuracy = np.mean(list(final_accuracies.values()))
        
        print(f"Pr√©cision moyenne finale: {avg_accuracy:.3f}")
        
        # Calculer l'oubli moyen
        total_forgetting = 0
        forgetting_count = 0
        
        for task_id in range(len(self.tasks) - 1):  # Exclure la derni√®re t√¢che
            if task_id in self.results['task_accuracies']:
                task_history = self.results['task_accuracies'][task_id]
                if len(task_history) >= 2:
                    max_acc = max(task_history[:-1])  # Max avant la derni√®re √©valuation
                    final_acc = task_history[-1]
                    forgetting = max_acc - final_acc
                    total_forgetting += forgetting
                    forgetting_count += 1
        
        avg_forgetting = total_forgetting / forgetting_count if forgetting_count > 0 else 0
        print(f"Oubli catastrophique moyen: {avg_forgetting:.3f}")
        
        return {
            'final_accuracies': final_accuracies,
            'average_accuracy': avg_accuracy,
            'average_forgetting': avg_forgetting,
            'task_history': dict(self.results['task_accuracies'])
        }
    
    def _simulate_evaluation(self, current_task: int) -> Dict[str, float]:
        """Simuler l'√©valuation avec d√©clin r√©aliste"""
        task_accuracies = {}
        
        for task_id in range(current_task + 1):
            if task_id == current_task:
                # Nouvelle t√¢che: bonne performance
                accuracy = 0.85 + random.uniform(-0.1, 0.1)
            else:
                # T√¢ches pr√©c√©dentes: d√©clin avec le temps
                tasks_since = current_task - task_id
                base_accuracy = 0.85
                # D√©clin de 10-20% par t√¢che ult√©rieure
                decay = tasks_since * random.uniform(0.1, 0.2)
                accuracy = max(0.3, base_accuracy - decay + random.uniform(-0.05, 0.05))
            
            task_accuracies[f"task_{task_id}"] = min(1.0, max(0.0, accuracy))
        
        return task_accuracies
    
    def save_results(self, results: Dict, filename: str):
        """Sauvegarder les r√©sultats"""
        with open(filename, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"R√©sultats sauvegard√©s dans {filename}")
    
    def plot_results(self, results: Dict):
        """Cr√©er des graphiques des r√©sultats"""
        plt.figure(figsize=(15, 10))
        
        # Graphique 1: √âvolution des pr√©cisions par t√¢che
        plt.subplot(2, 3, 1)
        for task_id, history in results['task_history'].items():
            plt.plot(range(len(history)), history, marker='o', label=f'T√¢che {task_id}')
        plt.title('√âvolution des pr√©cisions par t√¢che')
        plt.xlabel('√âvaluations successives')
        plt.ylabel('Pr√©cision')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Graphique 2: Pr√©cisions finales
        plt.subplot(2, 3, 2)
        tasks = list(results['final_accuracies'].keys())
        accuracies = list(results['final_accuracies'].values())
        plt.bar(tasks, accuracies, color='skyblue', alpha=0.7)
        plt.title('Pr√©cisions finales par t√¢che')
        plt.xlabel('T√¢che')
        plt.ylabel('Pr√©cision')
        plt.xticks(rotation=45)
        
        # Graphique 3: M√©triques globales
        plt.subplot(2, 3, 3)
        metrics = ['Pr√©cision\nmoyenne', 'Oubli\nmoyen']
        values = [results['average_accuracy'], results['average_forgetting']]
        colors = ['green', 'red']
        bars = plt.bar(metrics, values, color=colors, alpha=0.7)
        plt.title('M√©triques globales')
        plt.ylabel('Valeur')
        
        # Ajouter les valeurs sur les barres
        for bar, value in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.3f}', ha='center', va='bottom')
        
        # Graphique 4: Matrice d'oubli
        plt.subplot(2, 3, 4)
        num_tasks = len(results['task_history'])
        forgetting_matrix = np.zeros((num_tasks, num_tasks))
        
        for task_id, history in results['task_history'].items():
            task_id = int(task_id)
            for eval_point, accuracy in enumerate(history):
                if eval_point < num_tasks:
                    forgetting_matrix[task_id, eval_point] = accuracy
        
        plt.imshow(forgetting_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        plt.colorbar(label='Pr√©cision')
        plt.title('Matrice d\'oubli\n(T√¢che vs Temps)')
        plt.xlabel('Point d\'√©valuation')
        plt.ylabel('T√¢che')
        
        # Graphique 5: Classes par t√¢che
        plt.subplot(2, 3, 5)
        task_info = []
        for task in self.tasks:
            task_info.append(f"T{task['task_id']}")
        
        # Simuler la complexit√© par t√¢che
        complexities = [0.8, 0.9, 0.7, 0.85]  # Complexit√© simul√©e
        plt.bar(task_info, complexities, color='lightcoral', alpha=0.7)
        plt.title('Complexit√© simul√©e par t√¢che')
        plt.xlabel('T√¢che')
        plt.ylabel('Complexit√© (simul√©e)')
        
        # Graphique 6: R√©sum√© des techniques
        plt.subplot(2, 3, 6)
        plt.text(0.1, 0.8, "Exp√©rience d'Apprentissage Continu", fontsize=14, fontweight='bold')
        plt.text(0.1, 0.7, f"‚Ä¢ 4 t√¢ches s√©quentielles", fontsize=10)
        plt.text(0.1, 0.6, f"‚Ä¢ 4 classes par t√¢che", fontsize=10)
        plt.text(0.1, 0.5, f"‚Ä¢ Division des 16 classes RVL-CDIP", fontsize=10)
        plt.text(0.1, 0.4, f"‚Ä¢ √âvaluation de l'oubli catastrophique", fontsize=10)
        plt.text(0.1, 0.3, f"‚Ä¢ Pr√©cision finale: {results['average_accuracy']:.3f}", fontsize=10)
        plt.text(0.1, 0.2, f"‚Ä¢ Oubli moyen: {results['average_forgetting']:.3f}", fontsize=10)
        plt.xlim(0, 1)
        plt.ylim(0, 1)
        plt.axis('off')
        plt.title('R√©sum√© de l\'exp√©rience')
        
        plt.tight_layout()
        
        # Sauvegarder le graphique
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plot_filename = f"continual_learning_results_{timestamp}.png"
        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
        print(f"Graphiques sauvegard√©s dans {plot_filename}")
        plt.show()


def main():
    """Fonction principale"""
    print("üî¨ Exp√©rience d'Apprentissage Continu - Distillation de Connaissances")
    print("=" * 70)
    
    # Initialiser l'exp√©rience
    experiment = ContinualLearningExperiment(images_dir=".")
    
    # Afficher les t√¢ches
    print("T√¢ches d√©finies:")
    for task in experiment.tasks:
        print(f"  {task['description']}")
    
    # Ex√©cuter l'apprentissage s√©quentiel
    print("\nüöÄ D√©marrage de l'apprentissage s√©quentiel...")
    
    # Test avec approche naive (sans mitigation)
    results = experiment.run_sequential_learning(mitigation="naive")
    
    # Sauvegarder les r√©sultats
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_filename = f"continual_learning_results_{timestamp}.json"
    experiment.save_results(results, results_filename)
    
    # Cr√©er les graphiques
    experiment.plot_results(results)
    
    print("\n‚úÖ Exp√©rience termin√©e!")
    print(f"üìä R√©sultats: Pr√©cision moyenne = {results['average_accuracy']:.3f}")
    print(f"üß† Oubli catastrophique = {results['average_forgetting']:.3f}")
    
    # Suggestions pour la suite
    print("\nüí° Prochaines √©tapes sugg√©r√©es:")
    print("1. Impl√©menter la technique Rehearsal (rejeu d'exemples)")
    print("2. Tester Learning without Forgetting (LwF)")
    print("3. Comparer les performances avec/sans mitigation")
    print("4. Analyser l'impact sur diff√©rentes m√©triques")


if __name__ == "__main__":
    main() 